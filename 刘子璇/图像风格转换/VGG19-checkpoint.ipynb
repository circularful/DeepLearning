{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建VGG-19模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io \n",
    "import numpy as np \n",
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 层字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG19_LAYERS = {\n",
    "    'conv1_1','relu1_1','conv1_2','pool1',\n",
    "    \n",
    "    'conv2_1','relu2_1','conv2_2','pool2',\n",
    "    \n",
    "    'conv3_1','relu3_1','conv3_2','relu3_2','conv3_3','relu3_3','conv3_4','relu3_4','pool3',\n",
    "    \n",
    "    'conv4_1','relu4_1','conv4_2','relu4_2','conv4_3','relu4_3','conv4_4','relu4_4','pool4',\n",
    "    \n",
    "    'conv5_1','relu5_1','conv5_2','relu5_2','conv5_3','relu5_3','conv5_4','relu5_4'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载模型，并返回权重和平均像素\n",
    "def load_net(data_path):\n",
    "    data = scipy.io.loadmat(data_path)\n",
    "    if 'normalization' in data:\n",
    "        mean_pixel = np.mean(data['normalization'][0][0][0],axis=(0,1))\n",
    "    else:\n",
    "        mean_pixel = data['meta']['normalization'][0][0][0][0][2][0][0]\n",
    "    weights = data['layers'][0]\n",
    "    return weights,mean_pixel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.网络预加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_preloaded(weights, input_image, pooling):\n",
    "    net = {}\n",
    "    current = input_image\n",
    "    for i, name in enumerate(VGG19_LAYERS):\n",
    "        kind = name[:4]\n",
    "        if kind == 'conv':\n",
    "            if isinstance(weights[i][0][0][0][0], np.ndarray):\n",
    "                # old format\n",
    "                kernels, bias = weights[i][0][0][0][0]\n",
    "            else:\n",
    "                # new format\n",
    "                kernels, bias = weights[i][0][0][2][0]\n",
    "            # tensorflow: weights are [height, width, in_channels, out_channels]\n",
    "            kernels = np.transpose(kernels, (1, 0, 2, 3))\n",
    "            bias = bias.reshape(-1)\n",
    "            current = _conv_layer(current, kernels, bias)\n",
    "        elif kind == 'relu':\n",
    "            current = tf.nn.relu(current)\n",
    "        elif kind == 'pool':\n",
    "            current = _pool_layer(current, pooling)\n",
    "        net[name] = current\n",
    "\n",
    "    assert len(net) == len(VGG19_LAYERS)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.各层构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _conv_layer(input, weights, bias):\n",
    "    conv = tf.nn.conv2d(input, tf.constant(weights), strides=(1, 1, 1, 1),\n",
    "            padding='SAME')\n",
    "    return tf.nn.bias_add(conv, bias)\n",
    "\n",
    "\n",
    "def _pool_layer(input, pooling):\n",
    "    if pooling == 'avg':\n",
    "        return tf.nn.avg_pool(input, ksize=(1, 2, 2, 1), strides=(1, 2, 2, 1),\n",
    "                padding='SAME')\n",
    "    else:\n",
    "        return tf.nn.max_pool(input, ksize=(1, 2, 2, 1), strides=(1, 2, 2, 1),\n",
    "                padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.图片大小处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image, mean_pixel):\n",
    "    return image - mean_pixel\n",
    "\n",
    "\n",
    "def unprocess(image, mean_pixel):\n",
    "    return image + mean_pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
