{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import what we need\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import tensorflow as tf  # Import TensorFlow after Scipy or Scipy will break\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出图片的路径\n",
    "OUTPUT_DIR = '/home/liuzixuan/实训/02-用Python快速实现图片的风格迁移/output'\n",
    "# 风格图片的路径\n",
    "STYLE_IMAGE = '/home/liuzixuan/实训/02-用Python快速实现图片的风格迁移/img/star.jpg'\n",
    "# 内容图片的路径\n",
    "CONTENT_IMAGE = '/home/liuzixuan/实训/02-用Python快速实现图片的风格迁移/img'\n",
    "# VGG-19模型的路径\n",
    "VGG_MODEL = '/home/liuzixuan/实训/02-用Python快速实现图片的风格迁移/刘子璇/imagenet-vgg-verydeep-19.mat'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 所需常数定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出图片大小定义(224,224,3)\n",
    "IMAGE_WIDTH = 224\n",
    "IMAGE_HEIGHT = 224\n",
    "COLOR_CHANNELS = 3\n",
    "# 噪声比(与内容图像混合的噪声权重百分比)\n",
    "NOISE_RATIO = 0.6\n",
    "# Constant to put more emphasis on content loss.\n",
    "BETA = 5\n",
    "# Constant to put more emphasis on style loss.\n",
    "ALPHA = 100\n",
    "# 从VGG模型的输入中减去的平均值\n",
    "MEAN_VALUES = np.array([123.68, 116.779, 103.939]).reshape((1,1,1,3))\n",
    "# 训练次数\n",
    "ITERATIONS = 1000 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vgg_model(path):\n",
    "    \"\"\"\n",
    "    Returns a model for the purpose of 'painting' the picture.\n",
    "    Takes only the convolution layer weights and wrap using the TensorFlow\n",
    "    Conv2d, Relu and AveragePooling layer. VGG actually uses maxpool but\n",
    "    the paper indicates that using AveragePooling yields better results.\n",
    "    The last few fully connected layers are not used.\n",
    "    Here is the detailed configuration of the VGG model:\n",
    "        0 is conv1_1 (3, 3, 3, 64)\n",
    "        1 is relu\n",
    "        2 is conv1_2 (3, 3, 64, 64)\n",
    "        3 is relu    \n",
    "        4 is maxpool\n",
    "        5 is conv2_1 (3, 3, 64, 128)\n",
    "        6 is relu\n",
    "        7 is conv2_2 (3, 3, 128, 128)\n",
    "        8 is relu\n",
    "        9 is maxpool\n",
    "        10 is conv3_1 (3, 3, 128, 256)\n",
    "        11 is relu\n",
    "        12 is conv3_2 (3, 3, 256, 256)\n",
    "        13 is relu\n",
    "        14 is conv3_3 (3, 3, 256, 256)\n",
    "        15 is relu\n",
    "        16 is conv3_4 (3, 3, 256, 256)\n",
    "        17 is relu\n",
    "        18 is maxpool\n",
    "        19 is conv4_1 (3, 3, 256, 512)\n",
    "        20 is relu\n",
    "        21 is conv4_2 (3, 3, 512, 512)\n",
    "        22 is relu\n",
    "        23 is conv4_3 (3, 3, 512, 512)\n",
    "        24 is relu\n",
    "        25 is conv4_4 (3, 3, 512, 512)\n",
    "        26 is relu\n",
    "        27 is maxpool\n",
    "        28 is conv5_1 (3, 3, 512, 512)\n",
    "        29 is relu\n",
    "        30 is conv5_2 (3, 3, 512, 512)\n",
    "        31 is relu\n",
    "        32 is conv5_3 (3, 3, 512, 512)\n",
    "        33 is relu\n",
    "        34 is conv5_4 (3, 3, 512, 512)\n",
    "        35 is relu\n",
    "        36 is maxpool\n",
    "        37 is fullyconnected (7, 7, 512, 4096)\n",
    "        38 is relu\n",
    "        39 is fullyconnected (1, 1, 4096, 4096)\n",
    "        40 is relu\n",
    "        41 is fullyconnected (1, 1, 4096, 1000)\n",
    "        42 is softmax\n",
    "    \"\"\"\n",
    "    vgg = scipy.io.loadmat(path)\n",
    "\n",
    "    vgg_layers = vgg['layers']\n",
    "    # 定义权重函数(返回各层权重及偏置值)\n",
    "    def _weights(layer, expected_layer_name):\n",
    "        W = vgg_layers[0][layer][0][0][0][0][0]\n",
    "        b = vgg_layers[0][layer][0][0][0][0][1]\n",
    "        layer_name = vgg_layers[0][layer][0][0][-2]\n",
    "        assert layer_name == expected_layer_name\n",
    "        return W, b\n",
    "    # 定义各层函数\n",
    "    def _relu(conv2d_layer):\n",
    "        return tf.nn.relu(conv2d_layer)\n",
    "\n",
    "    def _conv2d(prev_layer, layer, layer_name):\n",
    "        W, b = _weights(layer, layer_name)\n",
    "        W = tf.constant(W)\n",
    "        b = tf.constant(np.reshape(b, (b.size)))\n",
    "        return tf.nn.conv2d(\n",
    "            prev_layer, filter=W, strides=[1, 1, 1, 1], padding='SAME') + b\n",
    "\n",
    "    def _conv2d_relu(prev_layer, layer, layer_name):\n",
    "        return _relu(_conv2d(prev_layer, layer, layer_name))\n",
    "\n",
    "    def _avgpool(prev_layer):\n",
    "        return tf.nn.avg_pool(prev_layer, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    # 构造图形模型\n",
    "    graph = {}\n",
    "    graph['input']   = tf.Variable(np.zeros((1, IMAGE_HEIGHT, IMAGE_WIDTH, COLOR_CHANNELS)), dtype = 'float32')\n",
    "    graph['conv1_1']  = _conv2d_relu(graph['input'], 0, 'conv1_1')\n",
    "    graph['conv1_2']  = _conv2d_relu(graph['conv1_1'], 2, 'conv1_2')\n",
    "    graph['avgpool1'] = _avgpool(graph['conv1_2'])\n",
    "    graph['conv2_1']  = _conv2d_relu(graph['avgpool1'], 5, 'conv2_1')\n",
    "    graph['conv2_2']  = _conv2d_relu(graph['conv2_1'], 7, 'conv2_2')\n",
    "    graph['avgpool2'] = _avgpool(graph['conv2_2'])\n",
    "    graph['conv3_1']  = _conv2d_relu(graph['avgpool2'], 10, 'conv3_1')\n",
    "    graph['conv3_2']  = _conv2d_relu(graph['conv3_1'], 12, 'conv3_2')\n",
    "    graph['conv3_3']  = _conv2d_relu(graph['conv3_2'], 14, 'conv3_3')\n",
    "    graph['conv3_4']  = _conv2d_relu(graph['conv3_3'], 16, 'conv3_4')\n",
    "    graph['avgpool3'] = _avgpool(graph['conv3_4'])\n",
    "    graph['conv4_1']  = _conv2d_relu(graph['avgpool3'], 19, 'conv4_1')\n",
    "    graph['conv4_2']  = _conv2d_relu(graph['conv4_1'], 21, 'conv4_2')\n",
    "    graph['conv4_3']  = _conv2d_relu(graph['conv4_2'], 23, 'conv4_3')\n",
    "    graph['conv4_4']  = _conv2d_relu(graph['conv4_3'], 25, 'conv4_4')\n",
    "    graph['avgpool4'] = _avgpool(graph['conv4_4'])\n",
    "    graph['conv5_1']  = _conv2d_relu(graph['avgpool4'], 28, 'conv5_1')\n",
    "    graph['conv5_2']  = _conv2d_relu(graph['conv5_1'], 30, 'conv5_2')\n",
    "    graph['conv5_3']  = _conv2d_relu(graph['conv5_2'], 32, 'conv5_3')\n",
    "    graph['conv5_4']  = _conv2d_relu(graph['conv5_3'], 34, 'conv5_4')\n",
    "    graph['avgpool5'] = _avgpool(graph['conv5_4'])\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 内容损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_loss_func(sess, model):\n",
    "    def _content_loss(p, x):\n",
    "        # 过滤器数量(即为通道数)\n",
    "        N = p.shape[3]\n",
    "        # ｆｅａｔｕｒｅ_map大小\n",
    "        M = p.shape[1] * p.shape[2]\n",
    "        return (1 / (4 * N * M)) * tf.reduce_sum(tf.pow(x - p, 2))\n",
    "    return _content_loss(sess.run(model['conv4_2']), model['conv4_2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 风格损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 若to have softer features可适当增加较高层(conv5_1)的权重,并降低下层(conv1_1)的权重\n",
    "# 若ｔｏ have harder features可降低较高层(conv5_1)的权重，并增加下层(conv1_1)的权重\n",
    "STYLE_LAYERS = [\n",
    "    ('conv1_1', 0.5),\n",
    "    ('conv2_1', 1.0),\n",
    "    ('conv3_1', 1.5),\n",
    "    ('conv4_1', 3.0),\n",
    "    ('conv5_1', 4.0),\n",
    "]\n",
    "\n",
    "def style_loss_func(sess, model):\n",
    "    # 定义ｇｒａｍ函数\n",
    "    def _gram_matrix(F, N, M):\n",
    "        Ft = tf.reshape(F, (M, N))\n",
    "        return tf.matmul(tf.transpose(Ft), Ft)\n",
    "\n",
    "    def _style_loss(a, x):\n",
    "        # 过滤器数量\n",
    "        N = a.shape[3]\n",
    "        # ｆｅａｔｕｒｅ_map大小\n",
    "        M = a.shape[1] * a.shape[2]\n",
    "        # 原始图像的样式表示\n",
    "        A = _gram_matrix(a, N, M)\n",
    "        # 生成图像的样式表示\n",
    "        G = _gram_matrix(x, N, M)\n",
    "        result = (1 / (4 * N**2 * M**2)) * tf.reduce_sum(tf.pow(G - A, 2))\n",
    "        return result\n",
    "\n",
    "    E = [_style_loss(sess.run(model[layer_name]), model[layer_name]) for layer_name, _ in STYLE_LAYERS]\n",
    "    W = [w for _, w in STYLE_LAYERS]\n",
    "    loss = sum([W[l] * E[l] for l in range(len(STYLE_LAYERS))])\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 噪声图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_noise_image(content_image, noise_ratio = NOISE_RATIO):\n",
    "    # 噪声图像:与内容图像以一定比例混合\n",
    "    noise_image = np.random.uniform(\n",
    "            -20, 20,\n",
    "            (1, IMAGE_HEIGHT, IMAGE_WIDTH, COLOR_CHANNELS)).astype('float32')\n",
    "    # 加权平均值\n",
    "    input_image = noise_image * noise_ratio + content_image * (1 - noise_ratio)\n",
    "    return input_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    image = scipy.misc.imread(path)\n",
    "    # 统一图片大小(1,224,224,3)\n",
    "    image = scipy.misc.imresize(image,(224,224,3))\n",
    "    image = np.reshape(image, ((1,) + image.shape))\n",
    "    # VGG模型的输入需要减去平均值\n",
    "    image = image - MEAN_VALUES\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 图片存储"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(path, image):\n",
    "    # 输出图片需要加回平均值\n",
    "    image = image + MEAN_VALUES\n",
    "    # 去掉第一个无用的维度，剩下的就是图像\n",
    "    image = image[0]\n",
    "    image = np.clip(image, 0, 255).astype('uint8')\n",
    "    scipy.misc.imsave(path, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Graph().as_default() as g:\n",
    "    content = tf.placeholder(shape=[None,224,224,3],dtype=tf.float32)\n",
    "    style = tf.placeholder(shape=[None,224,224,3],dtype=tf.float32)\n",
    "    # 模型加载\n",
    "    model = load_vgg_model(VGG_MODEL)\n",
    "    with tf.Session() as sess1:\n",
    "        # 内容损失\n",
    "        sess1.run(model['input'].assign(content))\n",
    "        content_loss = content_loss_func(sess1, model)\n",
    "    \n",
    "        # 风格损失\n",
    "        sess1.run(model['input'].assign(style))\n",
    "        style_loss = style_loss_func(sess1, model)\n",
    "        #总损失\n",
    "    total_loss = BETA * content_loss + ALPHA * style_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liuzixuan/test/lib/python3.5/site-packages/ipykernel_launcher.py:2: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  \n",
      "/home/liuzixuan/test/lib/python3.5/site-packages/ipykernel_launcher.py:4: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "content_images = []\n",
    "for i in range(1,6):\n",
    "    content_image = load_image(CONTENT_IMAGE+'/'+'img0'+str(i)+'.jpg')\n",
    "    content_images.append(content_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 224, 224, 3)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(content_images[0].shape)\n",
    "print(type(content_images[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot handle this data type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/test/lib/python3.5/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2489\u001b[0m             \u001b[0mtypekey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'typestr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2490\u001b[0;31m             \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fromarray_typemap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtypekey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2491\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ((1, 1, 224, 3), '<f8')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-5437c7e2280a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/test/lib/python3.5/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2490\u001b[0m             \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fromarray_typemap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtypekey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2491\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2492\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot handle this data type\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2493\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2494\u001b[0m         \u001b[0mrawmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot handle this data type"
     ]
    }
   ],
   "source": [
    "img = Image.fromarray(content_images[0])\n",
    "imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liuzixuan/test/lib/python3.5/site-packages/ipykernel_launcher.py:2: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  \n",
      "/home/liuzixuan/test/lib/python3.5/site-packages/ipykernel_launcher.py:4: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img0 1\n",
      "Iteration 0\n",
      "sum :  288513.8\n",
      "cost:  142955510000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liuzixuan/test/lib/python3.5/site-packages/ipykernel_launcher.py:7: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100\n",
      "sum :  -33583.406\n",
      "cost:  1937699100.0\n",
      "Iteration 200\n",
      "sum :  -222127.12\n",
      "cost:  1050811300.0\n",
      "Iteration 300\n",
      "sum :  -380975.78\n",
      "cost:  733068540.0\n",
      "Iteration 400\n",
      "sum :  -535154.75\n",
      "cost:  560131200.0\n",
      "Iteration 500\n",
      "sum :  -687636.2\n",
      "cost:  447830750.0\n",
      "Iteration 600\n",
      "sum :  -836054.75\n",
      "cost:  371268930.0\n",
      "Iteration 700\n",
      "sum :  -980406.3\n",
      "cost:  317821200.0\n",
      "Iteration 800\n",
      "sum :  -1119500.9\n",
      "cost:  278407550.0\n",
      "Iteration 900\n",
      "sum :  -1254101.5\n",
      "cost:  247162350.0\n",
      "###########################################################################\n",
      "img0 2\n",
      "Iteration 0\n",
      "sum :  -2314898.5\n",
      "cost:  138037130000.0\n",
      "Iteration 100\n",
      "sum :  -2446308.0\n",
      "cost:  2645558300.0\n",
      "Iteration 200\n",
      "sum :  -2563396.0\n",
      "cost:  1246245000.0\n",
      "Iteration 300\n",
      "sum :  -2653029.8\n",
      "cost:  802734100.0\n",
      "Iteration 400\n",
      "sum :  -2733878.5\n",
      "cost:  578023500.0\n",
      "Iteration 500\n",
      "sum :  -2807591.5\n",
      "cost:  442662430.0\n",
      "Iteration 600\n",
      "sum :  -2873041.2\n",
      "cost:  354036640.0\n",
      "Iteration 700\n",
      "sum :  -2932815.5\n",
      "cost:  294721440.0\n",
      "Iteration 800\n",
      "sum :  -2986962.0\n",
      "cost:  254042600.0\n",
      "Iteration 900\n",
      "sum :  -3035370.2\n",
      "cost:  226187780.0\n",
      "###########################################################################\n",
      "img0 3\n",
      "Iteration 0\n",
      "sum :  -2811482.5\n",
      "cost:  126652860000.0\n",
      "Iteration 100\n",
      "sum :  -3079935.8\n",
      "cost:  1692846200.0\n",
      "Iteration 200\n",
      "sum :  -3165389.0\n",
      "cost:  811132740.0\n",
      "Iteration 300\n",
      "sum :  -3239708.5\n",
      "cost:  544553340.0\n",
      "Iteration 400\n",
      "sum :  -3304435.2\n",
      "cost:  415248350.0\n",
      "Iteration 500\n",
      "sum :  -3362371.0\n",
      "cost:  338462080.0\n",
      "Iteration 600\n",
      "sum :  -3414123.0\n",
      "cost:  289511500.0\n",
      "Iteration 700\n",
      "sum :  -3459755.0\n",
      "cost:  254863500.0\n",
      "Iteration 800\n",
      "sum :  -3501038.0\n",
      "cost:  228329870.0\n",
      "Iteration 900\n",
      "sum :  -3537093.0\n",
      "cost:  207636830.0\n",
      "###########################################################################\n",
      "img0 4\n",
      "Iteration 0\n",
      "sum :  -1764256.5\n",
      "cost:  98874565000.0\n",
      "Iteration 100\n",
      "sum :  -1940993.2\n",
      "cost:  1568174500.0\n",
      "Iteration 200\n",
      "sum :  -2039961.0\n",
      "cost:  799954560.0\n",
      "Iteration 300\n",
      "sum :  -2131210.0\n",
      "cost:  547864060.0\n",
      "Iteration 400\n",
      "sum :  -2217045.5\n",
      "cost:  426519650.0\n",
      "Iteration 500\n",
      "sum :  -2300840.2\n",
      "cost:  349803740.0\n",
      "Iteration 600\n",
      "sum :  -2380669.8\n",
      "cost:  296810780.0\n",
      "Iteration 700\n",
      "sum :  -2455938.2\n",
      "cost:  258156900.0\n",
      "Iteration 800\n",
      "sum :  -2524643.0\n",
      "cost:  229653700.0\n",
      "Iteration 900\n",
      "sum :  -2587787.0\n",
      "cost:  207602400.0\n",
      "###########################################################################\n",
      "img0 5\n",
      "Iteration 0\n",
      "sum :  -282102.94\n",
      "cost:  99221180000.0\n",
      "Iteration 100\n",
      "sum :  -570609.25\n",
      "cost:  1821179000.0\n",
      "Iteration 200\n",
      "sum :  -753364.06\n",
      "cost:  1007273860.0\n",
      "Iteration 300\n",
      "sum :  -917327.6\n",
      "cost:  714835140.0\n",
      "Iteration 400\n",
      "sum :  -1078536.2\n",
      "cost:  553321600.0\n",
      "Iteration 500\n",
      "sum :  -1233823.6\n",
      "cost:  447044600.0\n",
      "Iteration 600\n",
      "sum :  -1378594.2\n",
      "cost:  371939400.0\n",
      "Iteration 700\n",
      "sum :  -1511292.2\n",
      "cost:  318241540.0\n",
      "Iteration 800\n",
      "sum :  -1632425.2\n",
      "cost:  279688350.0\n",
      "Iteration 900\n",
      "sum :  -1746042.5\n",
      "cost:  249959180.0\n",
      "###########################################################################\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g) as sess:\n",
    "    #优化器\n",
    "    optimizer = tf.train.AdamOptimizer(2.0)\n",
    "    train_step = optimizer.minimize(total_loss)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # 训练模型\n",
    "    \n",
    "    for step in range(1000):\n",
    "        #batch_images, batch_labels = mnist.train.next_batch(32)\n",
    "        \n",
    "        res_loss, _ = sess.run([total_loss, train_step], feed_dict={\n",
    "            content: content_image,\n",
    "            style: style_image\n",
    "        })\n",
    "        \n",
    "        # 输出代价并验证模型\n",
    "        if step % 100 == 0:\n",
    "            accs = []\n",
    "            for test_step in range(10000 // 32):\n",
    "                batch_images, batch_labels = mnist.test.next_batch(32)\n",
    "                res_acc = sess.run(acc, feed_dict={\n",
    "                    inputs: batch_images,\n",
    "                    labels: batch_labels\n",
    "                })\n",
    "                accs.append(res_acc)\n",
    "            accs = np.mean(accs)\n",
    "            print('step %5d, loss %2.4f, acc %.4f' % (step, res_loss, accs))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # 风格图片\n",
    "    #style_image = load_image(STYLE_IMAGE)\n",
    "    #imshow(style_image[0])\n",
    "\n",
    "    # 模型加载\n",
    "    #model = load_vgg_model(VGG_MODEL)\n",
    "    #print(model)\n",
    "\n",
    "    #print(content_image.shape)\n",
    "    #print(style_image.shape)\n",
    "    #for i  in range(1,6):\n",
    "        # 内容图片\n",
    "    #    content_image = load_image(CONTENT_IMAGE+'/'+'img0'+str(i)+'.jpg')\n",
    "    #    #imshow(content_image[0])\n",
    "    \n",
    "        # 输入图片\n",
    "    #    input_image = generate_noise_image(content_image)\n",
    "        #imshow(input_image[0])\n",
    "    \n",
    "        # 内容损失\n",
    "    #    sess.run(model['input'].assign(content_image))\n",
    "    #    content_loss = content_loss_func(sess, model)\n",
    "    \n",
    "        # 风格损失\n",
    "    #    sess.run(model['input'].assign(style_image))\n",
    "    #    style_loss = style_loss_func(sess, model)\n",
    "    \n",
    "        #总损失\n",
    "    #    total_loss = BETA * content_loss + ALPHA * style_loss\n",
    "    \n",
    "        #优化器\n",
    "    #    optimizer = tf.train.AdamOptimizer(2.0)\n",
    "    #    train_step = optimizer.minimize(total_loss)\n",
    "        \n",
    "    #    sess.run(tf.initialize_all_variables())\n",
    "    #    sess.run(model['input'].assign(input_image))\n",
    "    #    sess.run(tf.initialize_all_variables())\n",
    "    #    sess.run(model['input'].assign(input_image))\n",
    "        print('img0',i)\n",
    "        for j in range(ITERATIONS):\n",
    "            sess.run(train_step)\n",
    "            # 每迭代１００次输出一次\n",
    "            if j%100 == 0:\n",
    "                mixed_image = sess.run(model['input'])\n",
    "                print('Iteration %d' % (j))\n",
    "                print('sum : ', sess.run(tf.reduce_sum(mixed_image)))\n",
    "                print('cost: ', sess.run(total_loss))\n",
    "\n",
    "                if not os.path.exists(OUTPUT_DIR):\n",
    "                    os.mkdir(OUTPUT_DIR)\n",
    "\n",
    "                filename = OUTPUT_DIR + '/' + 'img0'+ str(i)+'_'+ str(j) + '.jpg' \n",
    "                save_image(filename, mixed_image)\n",
    "        print('###########################################################################')\n",
    "        saver.save(sess,'model'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
