{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import what we need\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import tensorflow as tf  # Import TensorFlow after Scipy or Scipy will break\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出图片的路径\n",
    "OUTPUT_DIR = '/home/liuzixuan/实训/02-用Python快速实现图片的风格迁移/output'\n",
    "# 风格图片的路径\n",
    "STYLE_IMAGE = '/home/liuzixuan/实训/02-用Python快速实现图片的风格迁移/img/star.jpg'\n",
    "# 内容图片的路径\n",
    "CONTENT_IMAGE = '/home/liuzixuan/实训/02-用Python快速实现图片的风格迁移/img'\n",
    "# VGG-19模型的路径\n",
    "VGG_MODEL = '/home/liuzixuan/实训/02-用Python快速实现图片的风格迁移/刘子璇/imagenet-vgg-verydeep-19.mat'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 所需常数定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出图片大小定义(224,224,3)\n",
    "IMAGE_WIDTH = 224\n",
    "IMAGE_HEIGHT = 224\n",
    "COLOR_CHANNELS = 3\n",
    "# 噪声比(与内容图像混合的噪声权重百分比)\n",
    "NOISE_RATIO = 0.6\n",
    "# Constant to put more emphasis on content loss.\n",
    "BETA = 5\n",
    "# Constant to put more emphasis on style loss.\n",
    "ALPHA = 100\n",
    "# 从VGG模型的输入中减去的平均值\n",
    "MEAN_VALUES = np.array([123.68, 116.779, 103.939]).reshape((1,1,1,3))\n",
    "# 训练次数\n",
    "ITERATIONS = 1000 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vgg_model(path):\n",
    "    \"\"\"\n",
    "    Returns a model for the purpose of 'painting' the picture.\n",
    "    Takes only the convolution layer weights and wrap using the TensorFlow\n",
    "    Conv2d, Relu and AveragePooling layer. VGG actually uses maxpool but\n",
    "    the paper indicates that using AveragePooling yields better results.\n",
    "    The last few fully connected layers are not used.\n",
    "    Here is the detailed configuration of the VGG model:\n",
    "        0 is conv1_1 (3, 3, 3, 64)\n",
    "        1 is relu\n",
    "        2 is conv1_2 (3, 3, 64, 64)\n",
    "        3 is relu    \n",
    "        4 is maxpool\n",
    "        5 is conv2_1 (3, 3, 64, 128)\n",
    "        6 is relu\n",
    "        7 is conv2_2 (3, 3, 128, 128)\n",
    "        8 is relu\n",
    "        9 is maxpool\n",
    "        10 is conv3_1 (3, 3, 128, 256)\n",
    "        11 is relu\n",
    "        12 is conv3_2 (3, 3, 256, 256)\n",
    "        13 is relu\n",
    "        14 is conv3_3 (3, 3, 256, 256)\n",
    "        15 is relu\n",
    "        16 is conv3_4 (3, 3, 256, 256)\n",
    "        17 is relu\n",
    "        18 is maxpool\n",
    "        19 is conv4_1 (3, 3, 256, 512)\n",
    "        20 is relu\n",
    "        21 is conv4_2 (3, 3, 512, 512)\n",
    "        22 is relu\n",
    "        23 is conv4_3 (3, 3, 512, 512)\n",
    "        24 is relu\n",
    "        25 is conv4_4 (3, 3, 512, 512)\n",
    "        26 is relu\n",
    "        27 is maxpool\n",
    "        28 is conv5_1 (3, 3, 512, 512)\n",
    "        29 is relu\n",
    "        30 is conv5_2 (3, 3, 512, 512)\n",
    "        31 is relu\n",
    "        32 is conv5_3 (3, 3, 512, 512)\n",
    "        33 is relu\n",
    "        34 is conv5_4 (3, 3, 512, 512)\n",
    "        35 is relu\n",
    "        36 is maxpool\n",
    "        37 is fullyconnected (7, 7, 512, 4096)\n",
    "        38 is relu\n",
    "        39 is fullyconnected (1, 1, 4096, 4096)\n",
    "        40 is relu\n",
    "        41 is fullyconnected (1, 1, 4096, 1000)\n",
    "        42 is softmax\n",
    "    \"\"\"\n",
    "    vgg = scipy.io.loadmat(path)\n",
    "\n",
    "    vgg_layers = vgg['layers']\n",
    "    # 定义权重函数(返回各层权重及偏置值)\n",
    "    def _weights(layer, expected_layer_name):\n",
    "        W = vgg_layers[0][layer][0][0][0][0][0]\n",
    "        b = vgg_layers[0][layer][0][0][0][0][1]\n",
    "        layer_name = vgg_layers[0][layer][0][0][-2]\n",
    "        assert layer_name == expected_layer_name\n",
    "        return W, b\n",
    "    # 定义各层函数\n",
    "    def _relu(conv2d_layer):\n",
    "        return tf.nn.relu(conv2d_layer)\n",
    "\n",
    "    def _conv2d(prev_layer, layer, layer_name):\n",
    "        W, b = _weights(layer, layer_name)\n",
    "        W = tf.constant(W)\n",
    "        b = tf.constant(np.reshape(b, (b.size)))\n",
    "        return tf.nn.conv2d(\n",
    "            prev_layer, filter=W, strides=[1, 1, 1, 1], padding='SAME') + b\n",
    "\n",
    "    def _conv2d_relu(prev_layer, layer, layer_name):\n",
    "        return _relu(_conv2d(prev_layer, layer, layer_name))\n",
    "\n",
    "    def _avgpool(prev_layer):\n",
    "        return tf.nn.avg_pool(prev_layer, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    # 构造图形模型\n",
    "    graph = {}\n",
    "    graph['input']   = tf.Variable(np.zeros((1, IMAGE_HEIGHT, IMAGE_WIDTH, COLOR_CHANNELS)), dtype = 'float32')\n",
    "    graph['conv1_1']  = _conv2d_relu(graph['input'], 0, 'conv1_1')\n",
    "    graph['conv1_2']  = _conv2d_relu(graph['conv1_1'], 2, 'conv1_2')\n",
    "    graph['avgpool1'] = _avgpool(graph['conv1_2'])\n",
    "    graph['conv2_1']  = _conv2d_relu(graph['avgpool1'], 5, 'conv2_1')\n",
    "    graph['conv2_2']  = _conv2d_relu(graph['conv2_1'], 7, 'conv2_2')\n",
    "    graph['avgpool2'] = _avgpool(graph['conv2_2'])\n",
    "    graph['conv3_1']  = _conv2d_relu(graph['avgpool2'], 10, 'conv3_1')\n",
    "    graph['conv3_2']  = _conv2d_relu(graph['conv3_1'], 12, 'conv3_2')\n",
    "    graph['conv3_3']  = _conv2d_relu(graph['conv3_2'], 14, 'conv3_3')\n",
    "    graph['conv3_4']  = _conv2d_relu(graph['conv3_3'], 16, 'conv3_4')\n",
    "    graph['avgpool3'] = _avgpool(graph['conv3_4'])\n",
    "    graph['conv4_1']  = _conv2d_relu(graph['avgpool3'], 19, 'conv4_1')\n",
    "    graph['conv4_2']  = _conv2d_relu(graph['conv4_1'], 21, 'conv4_2')\n",
    "    graph['conv4_3']  = _conv2d_relu(graph['conv4_2'], 23, 'conv4_3')\n",
    "    graph['conv4_4']  = _conv2d_relu(graph['conv4_3'], 25, 'conv4_4')\n",
    "    graph['avgpool4'] = _avgpool(graph['conv4_4'])\n",
    "    graph['conv5_1']  = _conv2d_relu(graph['avgpool4'], 28, 'conv5_1')\n",
    "    graph['conv5_2']  = _conv2d_relu(graph['conv5_1'], 30, 'conv5_2')\n",
    "    graph['conv5_3']  = _conv2d_relu(graph['conv5_2'], 32, 'conv5_3')\n",
    "    graph['conv5_4']  = _conv2d_relu(graph['conv5_3'], 34, 'conv5_4')\n",
    "    graph['avgpool5'] = _avgpool(graph['conv5_4'])\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 内容损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_loss_func(sess, model):\n",
    "    def _content_loss(p, x):\n",
    "        # 过滤器数量(即为通道数)\n",
    "        N = p.shape[3]\n",
    "        # ｆｅａｔｕｒｅ_map大小\n",
    "        M = p.shape[1] * p.shape[2]\n",
    "        return (1 / (4 * N * M)) * tf.reduce_sum(tf.pow(x - p, 2))\n",
    "    return _content_loss(sess.run(model['conv4_2']), model['conv4_2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 风格损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 若to have softer features可适当增加较高层(conv5_1)的权重,并降低下层(conv1_1)的权重\n",
    "# 若ｔｏ have harder features可降低较高层(conv5_1)的权重，并增加下层(conv1_1)的权重\n",
    "STYLE_LAYERS = [\n",
    "    ('conv1_1', 0.5),\n",
    "    ('conv2_1', 1.0),\n",
    "    ('conv3_1', 1.5),\n",
    "    ('conv4_1', 3.0),\n",
    "    ('conv5_1', 4.0),\n",
    "]\n",
    "\n",
    "def style_loss_func(sess, model):\n",
    "    # 定义ｇｒａｍ函数\n",
    "    def _gram_matrix(F, N, M):\n",
    "        Ft = tf.reshape(F, (M, N))\n",
    "        return tf.matmul(tf.transpose(Ft), Ft)\n",
    "\n",
    "    def _style_loss(a, x):\n",
    "        # 过滤器数量\n",
    "        N = a.shape[3]\n",
    "        # ｆｅａｔｕｒｅ_map大小\n",
    "        M = a.shape[1] * a.shape[2]\n",
    "        # 原始图像的样式表示\n",
    "        A = _gram_matrix(a, N, M)\n",
    "        # 生成图像的样式表示\n",
    "        G = _gram_matrix(x, N, M)\n",
    "        result = (1 / (4 * N**2 * M**2)) * tf.reduce_sum(tf.pow(G - A, 2))\n",
    "        return result\n",
    "\n",
    "    E = [_style_loss(sess.run(model[layer_name]), model[layer_name]) for layer_name, _ in STYLE_LAYERS]\n",
    "    W = [w for _, w in STYLE_LAYERS]\n",
    "    loss = sum([W[l] * E[l] for l in range(len(STYLE_LAYERS))])\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 噪声图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_noise_image(content_image, noise_ratio = NOISE_RATIO):\n",
    "    # 噪声图像:与内容图像以一定比例混合\n",
    "    noise_image = np.random.uniform(\n",
    "            -20, 20,\n",
    "            (1, IMAGE_HEIGHT, IMAGE_WIDTH, COLOR_CHANNELS)).astype('float32')\n",
    "    # 加权平均值\n",
    "    input_image = noise_image * noise_ratio + content_image * (1 - noise_ratio)\n",
    "    return input_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    image = scipy.misc.imread(path)\n",
    "    # 统一图片大小(1,224,224,3)\n",
    "    image = scipy.misc.imresize(image,(224,224,3))\n",
    "    image = np.reshape(image, ((1,) + image.shape))\n",
    "    # VGG模型的输入需要减去平均值\n",
    "    image = image - MEAN_VALUES\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 图片存储"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(path, image):\n",
    "    # 输出图片需要加回平均值\n",
    "    image = image + MEAN_VALUES\n",
    "    # 去掉第一个无用的维度，剩下的就是图像\n",
    "    image = image[0]\n",
    "    image = np.clip(image, 0, 255).astype('uint8')\n",
    "    scipy.misc.imsave(path, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected DataType for argument 'dtype' not <class 'tensorflow.python.client.session.Session'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/test/lib/python3.5/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mmake_type\u001b[0;34m(v, arg_name)\u001b[0m\n\u001b[1;32m    122\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/test/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py\u001b[0m in \u001b[0;36mas_dtype\u001b[0;34m(type_value)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot convert value %r to a TensorFlow DType.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: Cannot convert value <class 'tensorflow.python.client.session.Session'> to a TensorFlow DType.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-fa98e66d8840>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mstyle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;31m# 模型加载\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_vgg_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVGG_MODEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/test/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mplaceholder\u001b[0;34m(dtype, shape, name)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                        \"eager execution.\")\n\u001b[1;32m   1734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1736\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/test/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mplaceholder\u001b[0;34m(dtype, shape, name)\u001b[0m\n\u001b[1;32m   4918\u001b[0m   \u001b[0m_ctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4919\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_ctx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eager_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4920\u001b[0;31m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4921\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4922\u001b[0m       \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/test/lib/python3.5/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mmake_type\u001b[0;34m(v, arg_name)\u001b[0m\n\u001b[1;32m    124\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     raise TypeError(\"Expected DataType for argument '%s' not %s.\" %\n\u001b[0;32m--> 126\u001b[0;31m                     (arg_name, repr(v)))\n\u001b[0m\u001b[1;32m    127\u001b[0m   \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected DataType for argument 'dtype' not <class 'tensorflow.python.client.session.Session'>."
     ]
    }
   ],
   "source": [
    "#再写一个ｐｌａｃｅholder，用ｓｅｓｓ填补\n",
    "with tf.Graph().as_default() as g:\n",
    "    content = tf.placeholder(shape=[None,224,224,3],dtype=tf.float32)\n",
    "    style = tf.placeholder(shape=[None,224,224,3],dtype=tf.float32)\n",
    "    # 模型加载\n",
    "    model = load_vgg_model(VGG_MODEL)\n",
    "    \n",
    "    # 内容损失\n",
    "    sess.run(model['input'].assign(content))\n",
    "    content_loss = content_loss_func(sess, model)\n",
    "    \n",
    "    # 风格损失\n",
    "    sess.run(model['input'].assign(style))\n",
    "    style_loss = style_loss_func(sess, model)\n",
    "    #总损失\n",
    "    total_loss = BETA * content_loss + ALPHA * style_loss\n",
    "    #with tf.Session() as sess1:\n",
    "        # 内容损失\n",
    "    #    sess1.run(model['input'].assign(content))\n",
    "    #    content_loss = content_loss_func(sess1, model)\n",
    "    \n",
    "        # 风格损失\n",
    "    #    sess1.run(model['input'].assign(style))\n",
    "    #    style_loss = style_loss_func(sess1, model)\n",
    "        #总损失\n",
    "    #total_loss = BETA * content_loss + ALPHA * style_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.Graph??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liuzixuan/test/lib/python3.5/site-packages/ipykernel_launcher.py:2: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  \n",
      "/home/liuzixuan/test/lib/python3.5/site-packages/ipykernel_launcher.py:4: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "content_images = []\n",
    "for i in range(1,6):\n",
    "    content_image = load_image(CONTENT_IMAGE+'/'+'img0'+str(i)+'.jpg')\n",
    "    content_images.append(content_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 224, 224, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fca1d2e0198>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(content_images[0].shape)\n",
    "imshow(content_images[0][0])\n",
    "#print(type(content_images[0]))\n",
    "#print(content_images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liuzixuan/test/lib/python3.5/site-packages/ipykernel_launcher.py:2: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  \n",
      "/home/liuzixuan/test/lib/python3.5/site-packages/ipykernel_launcher.py:4: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img0 1\n",
      "Iteration 0\n",
      "sum :  288513.8\n",
      "cost:  142955510000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liuzixuan/test/lib/python3.5/site-packages/ipykernel_launcher.py:7: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100\n",
      "sum :  -33583.406\n",
      "cost:  1937699100.0\n",
      "Iteration 200\n",
      "sum :  -222127.12\n",
      "cost:  1050811300.0\n",
      "Iteration 300\n",
      "sum :  -380975.78\n",
      "cost:  733068540.0\n",
      "Iteration 400\n",
      "sum :  -535154.75\n",
      "cost:  560131200.0\n",
      "Iteration 500\n",
      "sum :  -687636.2\n",
      "cost:  447830750.0\n",
      "Iteration 600\n",
      "sum :  -836054.75\n",
      "cost:  371268930.0\n",
      "Iteration 700\n",
      "sum :  -980406.3\n",
      "cost:  317821200.0\n",
      "Iteration 800\n",
      "sum :  -1119500.9\n",
      "cost:  278407550.0\n",
      "Iteration 900\n",
      "sum :  -1254101.5\n",
      "cost:  247162350.0\n",
      "###########################################################################\n",
      "img0 2\n",
      "Iteration 0\n",
      "sum :  -2314898.5\n",
      "cost:  138037130000.0\n",
      "Iteration 100\n",
      "sum :  -2446308.0\n",
      "cost:  2645558300.0\n",
      "Iteration 200\n",
      "sum :  -2563396.0\n",
      "cost:  1246245000.0\n",
      "Iteration 300\n",
      "sum :  -2653029.8\n",
      "cost:  802734100.0\n",
      "Iteration 400\n",
      "sum :  -2733878.5\n",
      "cost:  578023500.0\n",
      "Iteration 500\n",
      "sum :  -2807591.5\n",
      "cost:  442662430.0\n",
      "Iteration 600\n",
      "sum :  -2873041.2\n",
      "cost:  354036640.0\n",
      "Iteration 700\n",
      "sum :  -2932815.5\n",
      "cost:  294721440.0\n",
      "Iteration 800\n",
      "sum :  -2986962.0\n",
      "cost:  254042600.0\n",
      "Iteration 900\n",
      "sum :  -3035370.2\n",
      "cost:  226187780.0\n",
      "###########################################################################\n",
      "img0 3\n",
      "Iteration 0\n",
      "sum :  -2811482.5\n",
      "cost:  126652860000.0\n",
      "Iteration 100\n",
      "sum :  -3079935.8\n",
      "cost:  1692846200.0\n",
      "Iteration 200\n",
      "sum :  -3165389.0\n",
      "cost:  811132740.0\n",
      "Iteration 300\n",
      "sum :  -3239708.5\n",
      "cost:  544553340.0\n",
      "Iteration 400\n",
      "sum :  -3304435.2\n",
      "cost:  415248350.0\n",
      "Iteration 500\n",
      "sum :  -3362371.0\n",
      "cost:  338462080.0\n",
      "Iteration 600\n",
      "sum :  -3414123.0\n",
      "cost:  289511500.0\n",
      "Iteration 700\n",
      "sum :  -3459755.0\n",
      "cost:  254863500.0\n",
      "Iteration 800\n",
      "sum :  -3501038.0\n",
      "cost:  228329870.0\n",
      "Iteration 900\n",
      "sum :  -3537093.0\n",
      "cost:  207636830.0\n",
      "###########################################################################\n",
      "img0 4\n",
      "Iteration 0\n",
      "sum :  -1764256.5\n",
      "cost:  98874565000.0\n",
      "Iteration 100\n",
      "sum :  -1940993.2\n",
      "cost:  1568174500.0\n",
      "Iteration 200\n",
      "sum :  -2039961.0\n",
      "cost:  799954560.0\n",
      "Iteration 300\n",
      "sum :  -2131210.0\n",
      "cost:  547864060.0\n",
      "Iteration 400\n",
      "sum :  -2217045.5\n",
      "cost:  426519650.0\n",
      "Iteration 500\n",
      "sum :  -2300840.2\n",
      "cost:  349803740.0\n",
      "Iteration 600\n",
      "sum :  -2380669.8\n",
      "cost:  296810780.0\n",
      "Iteration 700\n",
      "sum :  -2455938.2\n",
      "cost:  258156900.0\n",
      "Iteration 800\n",
      "sum :  -2524643.0\n",
      "cost:  229653700.0\n",
      "Iteration 900\n",
      "sum :  -2587787.0\n",
      "cost:  207602400.0\n",
      "###########################################################################\n",
      "img0 5\n",
      "Iteration 0\n",
      "sum :  -282102.94\n",
      "cost:  99221180000.0\n",
      "Iteration 100\n",
      "sum :  -570609.25\n",
      "cost:  1821179000.0\n",
      "Iteration 200\n",
      "sum :  -753364.06\n",
      "cost:  1007273860.0\n",
      "Iteration 300\n",
      "sum :  -917327.6\n",
      "cost:  714835140.0\n",
      "Iteration 400\n",
      "sum :  -1078536.2\n",
      "cost:  553321600.0\n",
      "Iteration 500\n",
      "sum :  -1233823.6\n",
      "cost:  447044600.0\n",
      "Iteration 600\n",
      "sum :  -1378594.2\n",
      "cost:  371939400.0\n",
      "Iteration 700\n",
      "sum :  -1511292.2\n",
      "cost:  318241540.0\n",
      "Iteration 800\n",
      "sum :  -1632425.2\n",
      "cost:  279688350.0\n",
      "Iteration 900\n",
      "sum :  -1746042.5\n",
      "cost:  249959180.0\n",
      "###########################################################################\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g) as sess:\n",
    "    #优化器\n",
    "    optimizer = tf.train.AdamOptimizer(2.0)\n",
    "    train_step = optimizer.minimize(total_loss)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # 风格图片\n",
    "    style_image = load_image(STYLE_IMAGE)\n",
    "    #imshow(style_image[0])\n",
    "    \n",
    "    # 训练模型\n",
    "    batch_size = 1\n",
    "    group_train = len(content_images)//batch_size\n",
    "    for step in range(1000):\n",
    "        #batch_images, batch_labels = mnist.train.next_batch(32)\n",
    "        loss = []\n",
    "        for train_step in range(group_train):\n",
    "            batch_images = content_images[train_step*batch_size:train_step*batch_size+batch_size,:]\n",
    "            res_loss,_ = sess.run([loss,train_step],feed_dict={content:batch_images,style:style_image})\n",
    "            loss.append(res_loss)\n",
    "        avg_loss = np.mean(loss)\n",
    "        print('step %5d, loss %2.4f' % (step, avg_loss))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # 风格图片\n",
    "    #style_image = load_image(STYLE_IMAGE)\n",
    "    #imshow(style_image[0])\n",
    "\n",
    "    # 模型加载\n",
    "    #model = load_vgg_model(VGG_MODEL)\n",
    "    #print(model)\n",
    "\n",
    "    #print(content_image.shape)\n",
    "    #print(style_image.shape)\n",
    "    #for i  in range(1,6):\n",
    "        # 内容图片\n",
    "    #    content_image = load_image(CONTENT_IMAGE+'/'+'img0'+str(i)+'.jpg')\n",
    "    #    #imshow(content_image[0])\n",
    "    \n",
    "        # 输入图片\n",
    "    #    input_image = generate_noise_image(content_image)\n",
    "        #imshow(input_image[0])\n",
    "    \n",
    "        # 内容损失\n",
    "    #    sess.run(model['input'].assign(content_image))\n",
    "    #    content_loss = content_loss_func(sess, model)\n",
    "    \n",
    "        # 风格损失\n",
    "    #    sess.run(model['input'].assign(style_image))\n",
    "    #    style_loss = style_loss_func(sess, model)\n",
    "    \n",
    "        #总损失\n",
    "    #    total_loss = BETA * content_loss + ALPHA * style_loss\n",
    "    \n",
    "        #优化器\n",
    "    #    optimizer = tf.train.AdamOptimizer(2.0)\n",
    "    #    train_step = optimizer.minimize(total_loss)\n",
    "        \n",
    "    #    sess.run(tf.initialize_all_variables())\n",
    "    #    sess.run(model['input'].assign(input_image))\n",
    "    #    sess.run(tf.initialize_all_variables())\n",
    "    #    sess.run(model['input'].assign(input_image))\n",
    "        print('img0',i)\n",
    "        for j in range(ITERATIONS):\n",
    "            sess.run(train_step)\n",
    "            # 每迭代１００次输出一次\n",
    "            if j%100 == 0:\n",
    "                mixed_image = sess.run(model['input'])\n",
    "                print('Iteration %d' % (j))\n",
    "                print('sum : ', sess.run(tf.reduce_sum(mixed_image)))\n",
    "                print('cost: ', sess.run(total_loss))\n",
    "\n",
    "                if not os.path.exists(OUTPUT_DIR):\n",
    "                    os.mkdir(OUTPUT_DIR)\n",
    "\n",
    "                filename = OUTPUT_DIR + '/' + 'img0'+ str(i)+'_'+ str(j) + '.jpg' \n",
    "                save_image(filename, mixed_image)\n",
    "        print('###########################################################################')\n",
    "        saver.save(sess,'model'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
